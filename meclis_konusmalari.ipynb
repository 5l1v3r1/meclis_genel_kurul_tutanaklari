{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TBMM OTURUM TUTANAKLARININ İNDİRİLMESİ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilk_hedef = requests.get(\"https://www.tbmm.gov.tr/tutanak/tutanaklar.htm\").content\n",
    "soup1=BeautifulSoup(ilk_hedef)\n",
    "\n",
    "urls_1=[]\n",
    "for i in soup1.find_all(\"a\", href=True):\n",
    "    urls_1.append(str(i).split('=\"')[1].split('\" s')[0])\n",
    "\n",
    "# YUKARIDA ELDE EDİLEN urls_1 LİSTESİ KULLANILARAK urls_dict (TARİH:LİNK) ŞEKLİNDE ELDE EDİLİYOR\n",
    "\n",
    "urls_dict = {}\n",
    "\n",
    "for url in urls_1:\n",
    "    ikinci_hedef = requests.get(url).content\n",
    "    soup2 = BeautifulSoup(ikinci_hedef)\n",
    "\n",
    "    for i in soup2.find_all(\"a\", href=True):\n",
    "        if (not \"Özet\" in i) and (not \"Açık Oylama Sonuçları\" in i) and (not \"Sesli Özet\" in i) and (not \"İşaret Dili\" in i):             \n",
    "            j = str(i).split('=\"')[1].split('\">')[0]\n",
    "            k = parse(str(i.parent.next_sibling.next_sibling).split(\"d>\")[1].split(\" \")[0])\n",
    "            if (\"ham\" in j) or (\"bas\" in j):\n",
    "                urls_dict[k] = j\n",
    "      \n",
    "\n",
    "\n",
    "    \n",
    "# urls_dict SÖZLÜĞÜ YEDEKLEMEK AMACIYLA 'urls_dict.txt' DOSYASINA KAYDEDİLDİ\n",
    "# with open('urls_dict.txt', 'w') as f:\n",
    "#     print(urls_dict, file=f)  \n",
    "\n",
    "\n",
    "urls_yedek = urls_dict.copy()         # YEDEĞİ ALMAK HER ZAMAN LAZIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'sleep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-f4b809e36f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0murls_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m                                  \u001b[1;31m# BÖYLECE HERHANGİ BİR SEBEPLE İŞLEM YARIDA KESİLİRSE SONRA DEVAM EDEBİLİRİZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                    \u001b[1;31m# SİTEYİ BOĞMAMAK İÇİN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'sleep'"
     ]
    }
   ],
   "source": [
    "# for u in urls_dict.values():\n",
    "#     print(u)\n",
    "# b=str(soup2.find(\"a\", href=True)).split('=\"')[1].split('\">')[0]\n",
    "# # print(str(soup2.find(\"a\", href=True).parent.next_sibling.next_sibling).split(\"d>\")[1].split(\" \")[0])\n",
    "# a=parse(str(soup2.find(\"a\", href=True).parent.next_sibling.next_sibling).split(\"d>\")[1].split(\"</t\")[0])\n",
    "# # print(soup2.prettify())\n",
    "# urls_3[a] = b\n",
    "# print(urls_3)\n",
    "# print(a,b)\n",
    "\n",
    "\n",
    "for key,value in urls_dict.items():\n",
    "    req = requests.get(value).content\n",
    "    soup = BeautifulSoup(req)\n",
    "    text = soup.get_text().replace(\"\\xa0\",\"\")\n",
    "    date = key.strftime(\"%Y-%m-%d\")\n",
    "    with open(f\"tutanaklar/{date}.txt\", 'wb') as f:\n",
    "        f.write(text.encode(\"utf-8\"))\n",
    "                                      \n",
    "    with open(\"tamamlanan_urller.txt\", 'w') as f:      # PROGRAM KAPANIRSA TAMAMLANMIŞ İŞLEMLER KAYBEDİLMESİN DİYE\n",
    "        f.write(value)\n",
    "        f.write(\"\\r\\n\")\n",
    "    urls_dict.pop(key)                                  # BÖYLECE HERHANGİ BİR SEBEPLE İŞLEM YARIDA KESİLİRSE SONRA DEVAM EDEBİLİRİZ\n",
    "    time.sleep(random.randint(4,10))                    # SİTEYİ BOĞMAMAK İÇİN\n",
    "#     break\n",
    "\n",
    "    \n",
    "#     import time\n",
    "# timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# print timestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BURADA URL GİRDİLERİ FOR DÖNGÜSÜNE GİRECEK\n",
    "# BUNUN ÖNCESİNE ilk_hedef ve ikinci_hedef KISIMLARI GELECEK\n",
    "\n",
    "# url = \"https://www.tbmm.gov.tr/tutanak/donem27/yil3/ham/b08501h.htm\"\n",
    "# url = \"https://www.tbmm.gov.tr/tutanak/donem21/yil2/bas/b119m.htm\"\n",
    "# site = requests.get(url).content\n",
    "time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÜTÜN SAYFANIN TEXT'İ ALINDI - FARKLI ŞEKİLDE TASARLANMIŞ SAYFALARLA AYRI AYRI UĞRAŞMAKTANSA BU DAHA KOLAY OLABİLİR\n",
    "\n",
    "# soup = BeautifulSoup.BeautifulSoup(site.decode('utf-8','ignore'))\n",
    "# soup = BeautifulSoup(site)\n",
    "# q = soup.get_text().replace(\"\\xa0\",\"\")               #.replace(\"\\r\\n\",\" \").lower()\n",
    "\n",
    "# zxc = []\n",
    "# for asdqew in q.split(\"birleşim\"):\n",
    "#     zxc.append(asdqew)\n",
    "# print(zxc)\n",
    "# print(q[198:][:12])\n",
    "# print(q[30000:][:600])\n",
    "# print(q[:1000])\n",
    "# x = open(\"tutanaklar/test.txt\", \"wb\")\n",
    "# x.write(q.encode(\"utf-8\"))\n",
    "# x.close()\n",
    "# print(type(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BU KISIM BİR ÖNCEKİ HÜCRENİN SONUÇLARINI AYIKLAMAK İÇİN YENİDEN DÜZENLENMELİ\n",
    "\n",
    "'''\n",
    "i = \"\"\n",
    "for liste in soup.find_all(\"p\", class_=\"GENELKURUL\"):\n",
    "    i+=liste.text.replace(\"\\r\\n\",\" \")+\" \"\n",
    "i.replace(\"  \",\" \")\n",
    "# i.replace(\"\\r\\n\",\" \")\n",
    "\n",
    "\n",
    "asd = i.split()\n",
    "for kelime in range(len(asd)):\n",
    "    if ((asd[kelime].isupper() and asd[kelime+1].isupper()) or asd[kelime]==\"BAŞKAN\") and not asd[kelime+1].startswith(\"PART\"):\n",
    "        if asd[kelime-1].isupper() and asd[kelime].isupper() and asd[kelime+1].isupper():\n",
    "            pass\n",
    "        else:\n",
    "            asd[kelime]=\"\\n\"+asd[kelime]\n",
    "qwe = \" \".join(asd)\n",
    "print(qwe)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÜTÜN İŞLEM BİTTİĞİNDE CSV DOSYASI HALİNDE KAYDEDİLMELİ\n",
    "\n",
    "f = open(\"test.txt\",'w')\n",
    "f.write(i)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
